{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolator script\n",
    "\n",
    "This serves to fill missing values into the sign lang data since each example is not the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from scipy.interpolate import interp1d\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/pickled/x.pickle', 'rb') as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "with open('./data/pickled/y.pickle', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is the version of the interpolator that uses the numpy.interp linear interpolator\n",
    "\n",
    "def npinterpolate(data):\n",
    "    \n",
    "    def nanfinder(x):\n",
    "        return np.isnan(x), lambda z: z.nonzero()[0]\n",
    "    \n",
    "    #np.random.seed(26)\n",
    "    x_interp = []\n",
    "    \n",
    "    \n",
    "    for row in range(data.shape[0]): # For each of 2565 rows\n",
    "        holder = []\n",
    "        dim = np.int(np.count_nonzero(~np.isnan(data[row]))/22) # return the number of observations in this example\n",
    "        for i in range(1,23): # For each of 22 variables\n",
    "            scaffold = np.array([np.nan]*136) # (136,) array of nans\n",
    "            current_var = data[row,i*dim-dim:i*dim] # return array with current var of size (dim,)\n",
    "            randpts = np.sort(random.sample(range(136),dim)) # return array of random points of size (dim,)\n",
    "            scaffold[randpts] = current_var[:]\n",
    "            nans,x = nanfinder(scaffold)\n",
    "            scaffold[nans] = np.interp(x(nans),x(~nans),scaffold[~nans])\n",
    "            holder.extend(scaffold.tolist()) # long list of values, 1D\n",
    "        x_interp.extend(holder) # even longer list of values, 1D\n",
    "    return np.array(x_interp).reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the version of the interpolator script that uses the scipy interpolator with kind = slinear\n",
    "\n",
    "def scipyinterpolate(data):\n",
    "    x_interp = []\n",
    "    for row in range(data.shape[0]): # For each of 2565 rows\n",
    "        holder = []\n",
    "        dim = np.int(np.count_nonzero(~np.isnan(data[row]))/22)\n",
    "        for i in range(1,23): # For each of 22 variables\n",
    "            scaffold = np.full(2992,np.nan)\n",
    "            old_x = data[row,i*dim-dim:i*dim]\n",
    "            old_y= [1]+np.sort(random.sample(range(2,136),dim-2)).tolist()+[136]\n",
    "            new_y = [x for x in range(2,136) if np.in1d(range(2,136),old_y).tolist()[range(2,136).index(x)] == False]\n",
    "            f = interp1d(old_y,old_x,kind=1)\n",
    "            new_x = f(new_y)\n",
    "            scaffold[[x-1 for x in old_y]] = old_x[:]\n",
    "            scaffold[[x-1 for x in new_y]] = new_x[:]\n",
    "            holder.extend(scaffold) # even longer list of values, 1D\n",
    "        x_interp.extend(holder)\n",
    "    return np.array(x_interp).reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_interp = npinterpolate(x)\n",
    "#x_scipyinterp = scipyinterpolate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_interp = MinMaxScaler().fit_transform(x_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/pickled/x_interp.pickle', 'wb') as f:\n",
    "    pickle.dump(x_interp, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#np.save('data/x_npinterp.npy',x_npinterp)\n",
    "#np.save('x_scipyinterp.npy',x_scipyinterp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find min / max / mean sizes of data\n",
    "\n",
    "size = []\n",
    "for i in range(x.shape[0]):\n",
    "    size.append(np.count_nonzero(~np.isnan(x[i]))/22)\n",
    "np.max(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-fb0f1a4baef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tsd\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# m features X 22 meausrements / ravel makes it one line\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(.+?)-[0-9]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "# Without  ravel / padding with np.nans / etc\n",
    "# Just gives the raw values. Each would be a different size.\n",
    "# Initialize empty numpy arrays\n",
    "x = np.array(0)\n",
    "y = np.array(0)\n",
    "data = np.empty(0)\n",
    "\n",
    "for root, dirs, files in os.walk('data/tctodd'):\n",
    "    for i,fn in enumerate(files):\n",
    "        if fn.endswith(\"tsd\"):\n",
    "            vals = np.loadtxt(os.path.join(root,fn),delimiter='\\t') # m features X 22 meausrements / ravel makes it one line\n",
    "            x[i] = vals\n",
    "            y[i] = re.search('(.+?)-[0-9]',fn).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3232878,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1125.07194785  +0.j        ,    29.38434614 -38.32643892j,\n",
       "        -130.68569558-350.2620491j , ...,    63.63042299-103.20299939j,\n",
       "        -130.68569558+350.2620491j ,    29.38434614 +38.32643892j])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_normed = {k: (data-np.mean(data))/np.std(data) for k, data in my_time_series.items()}\n",
    "\n",
    "maxlength = max(my_time_series)\n",
    "\n",
    "x_interped = {k: np.interp(np.linspace(0, 1, maxlength), np.linspace(0, 1, k), data) for k, data in y_normed.items()}\n",
    "\n",
    "[plot(data) for data in x_interped.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.11111111,  0.22222222,  0.33333333,  0.44444444,\n",
       "        0.55555556,  0.66666667,  0.77777778,  0.88888889,  1.        ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
